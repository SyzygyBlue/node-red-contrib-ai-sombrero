<script type="text/javascript">
    RED.nodes.registerType('llm-config', {
        category: 'config',
        icon: "font-awesome/fa-hat-cowboy",
        defaults: {
            name: { value: "" },
            provider: { value: "openai" },
            model: { value: "" },
            baseUrl: { value: "" },
            version: { value: "" },
            options: { value: {} }
        },
        credentials: {
            apiKey: { type: "password" }
        },
        label: function() {
            return this.name || "LLM Config";
        },
        oneditprepare: function() {
            const node = this;
            
            // Set initial values for provider-specific fields
            if (node.baseUrl) {
                const provider = node.provider || 'openai';
                $(`#node-config-input-${provider}-baseUrl`).val(node.baseUrl);
            }
            
            // Provider selection change handler
            $("#node-config-input-provider").on("change", function() {
                const provider = $(this).val();
                // Hide all provider-specific sections first
                $(".provider-specific").hide();
                // Show the selected provider section
                $("#" + provider + "-config").show();
                // Toggle API key visibility (not needed for Ollama)
                const apiKeyRow = $("#node-config-input-apiKey").closest('.form-row');
                if (provider === 'ollama') {
                    apiKeyRow.hide();
                } else {
                    apiKeyRow.show();
                }
                
                // Update model dropdown based on provider
                updateModelOptions(provider);
            });
            
            // Initialize provider sections
            $("#node-config-input-provider").trigger("change");
            
            function updateModelOptions(provider) {
                const modelSelect = $("#node-config-input-model");
                modelSelect.empty();
                
                // Add provider-specific model options
                switch(provider) {
                    case "openai":
                        modelSelect.append(new Option("gpt-4o", "gpt-4o"));
                        modelSelect.append(new Option("gpt-4-turbo", "gpt-4-turbo"));
                        modelSelect.append(new Option("gpt-4", "gpt-4"));
                        modelSelect.append(new Option("gpt-3.5-turbo", "gpt-3.5-turbo"));
                        break;
                    case "anthropic":
                        modelSelect.append(new Option("claude-3-opus", "claude-3-opus"));
                        modelSelect.append(new Option("claude-3-sonnet", "claude-3-sonnet"));
                        modelSelect.append(new Option("claude-3-haiku", "claude-3-haiku"));
                        break;
                    case "google":
                        modelSelect.append(new Option("gemini-1.5-pro", "gemini-1.5-pro"));
                        modelSelect.append(new Option("gemini-1.5-flash", "gemini-1.5-flash"));
                        modelSelect.append(new Option("gemini-1.0-pro", "gemini-1.0-pro"));
                        break;
                    case "azure":
                        modelSelect.append(new Option("gpt-4", "gpt-4"));
                        modelSelect.append(new Option("gpt-35-turbo", "gpt-35-turbo"));
                        break;
                    case "deepseek":
                        modelSelect.append(new Option("deepseek-chat", "deepseek-chat"));
                        modelSelect.append(new Option("deepseek-coder", "deepseek-coder"));
                        break;
                    case "ollama":
                        modelSelect.append(new Option("deepseek-r1", "deepseek-r1"));
                        modelSelect.append(new Option("mistral:7b", "mistral:7b"));
                        modelSelect.append(new Option("llama3", "llama3"));
                        modelSelect.append(new Option("codellama:7b-instruct", "codellama:7b-instruct"));
                        modelSelect.append(new Option("devstral:28b", "devstral"));
                        modelSelect.append(new Option("mixtral", "mixtral"));
                        modelSelect.append(new Option("magistral", "magistral"));
                        break;
                    case "magistral":
                        modelSelect.append(new Option("magistral-7b", "magistral-7b"));
                        modelSelect.append(new Option("magistral-13b", "magistral-13b"));
                        break;
                    case "xai":
                        modelSelect.append(new Option("grok-1", "grok-1"));
                        break;
                }
                
                // Select the current model if it exists
                if (node.model) {
                    modelSelect.val(node.model);
                }
            }
        },
        oneditsave: function() {
            // Get the current provider
            const provider = $("#node-config-input-provider").val();
            
            // Get the baseUrl from the provider-specific input
            this.baseUrl = $(`#node-config-input-${provider}-baseUrl`).val();
        }
    });
</script>

<script type="text/x-red" data-template-name="llm-config">
    <div class="form-row">
        <label for="node-config-input-name"><i class="fa fa-tag"></i> Name</label>
        <input type="text" id="node-config-input-name" placeholder="Name">
    </div>
    
    <div class="form-row">
        <label for="node-config-input-provider"><i class="fa fa-server"></i> Provider</label>
        <select id="node-config-input-provider">
            <option value="openai">OpenAI</option>
            <option value="anthropic">Anthropic</option>
            <option value="google">Google</option>
            <option value="azure">Azure OpenAI</option>
            <option value="ollama">Ollama (local)</option>
            <option value="deepseek">Deepseek</option>
            <option value="xai">xAI</option>
            <option value="magistral">Magistral</option>
        </select>
    </div>
    
    <div class="form-row">
        <label for="node-config-input-model"><i class="fa fa-cube"></i> Model</label>
        <select id="node-config-input-model"></select>
    </div>
    
    <div class="form-row">
        <label for="node-config-input-apiKey"><i class="fa fa-key"></i> API Key</label>
        <input type="password" id="node-config-input-apiKey">
    </div>
    
    <!-- Provider-specific configurations -->
    <div id="openai-config" class="provider-specific">
        <div class="form-row">
            <label for="node-config-input-openai-baseUrl"><i class="fa fa-link"></i> Base URL</label>
            <input type="text" id="node-config-input-openai-baseUrl" class="baseUrl-input" placeholder="https://api.openai.com/v1">
        </div>
    </div>
    
    <div id="azure-config" class="provider-specific">
        <div class="form-row">
            <label for="node-config-input-azure-baseUrl"><i class="fa fa-link"></i> Endpoint</label>
            <input type="text" id="node-config-input-azure-baseUrl" class="baseUrl-input" placeholder="https://your-resource.openai.azure.com">
        </div>
        <div class="form-row">
            <label for="node-config-input-version"><i class="fa fa-code-branch"></i> API Version</label>
            <input type="text" id="node-config-input-version" placeholder="2023-05-15">
        </div>
    </div>
    
    <div id="anthropic-config" class="provider-specific">
        <div class="form-row">
            <label for="node-config-input-anthropic-baseUrl"><i class="fa fa-link"></i> Base URL</label>
            <input type="text" id="node-config-input-anthropic-baseUrl" class="baseUrl-input" placeholder="https://api.anthropic.com">
        </div>
    </div>
    
    <div id="google-config" class="provider-specific">
        <div class="form-row">
            <label for="node-config-input-google-baseUrl"><i class="fa fa-link"></i> Base URL</label>
            <input type="text" id="node-config-input-google-baseUrl" class="baseUrl-input" placeholder="https://generativelanguage.googleapis.com">
        </div>
    </div>
    
    <div id="deepseek-config" class="provider-specific">
        <div class="form-row">
            <label for="node-config-input-deepseek-baseUrl"><i class="fa fa-link"></i> Base URL</label>
            <input type="text" id="node-config-input-deepseek-baseUrl" class="baseUrl-input" placeholder="https://api.deepseek.com">
        </div>
    </div>
    
    <div id="xai-config" class="provider-specific">
        <div class="form-row">
            <label for="node-config-input-xai-baseUrl"><i class="fa fa-link"></i> Base URL</label>
            <input type="text" id="node-config-input-xai-baseUrl" class="baseUrl-input" placeholder="https://api.xai.com">
        </div>
    </div>
</script>

<script type="text/x-red" data-help-name="llm-config">
    <p>LLM Configuration node for connecting to various LLM providers.</p>
    <h3>Details</h3>
    <p>This configuration node stores the connection details for various LLM providers:</p>
    <ul>
        <li><b>OpenAI</b> - Connect to OpenAI's API with models like GPT-4o, GPT-4, and GPT-3.5</li>
        <li><b>Anthropic</b> - Connect to Anthropic's Claude models</li>
        <li><b>Google</b> - Connect to Google's Gemini models</li>
        <li><b>Azure OpenAI</b> - Connect to Azure-hosted OpenAI models</li>
        <li><b>Deepseek</b> - Connect to Deepseek's AI models</li>
        <li><b>xAI</b> - Connect to xAI's Grok models</li>
    </ul>
    <h3>Configuration</h3>
    <ul>
        <li><b>Name</b> - A name for this configuration</li>
        <li><b>Provider</b> - The LLM provider to use</li>
        <li><b>Model</b> - The specific model to use</li>
        <li><b>API Key</b> - Your API key for the selected provider</li>
        <li><b>Base URL</b> - Optional custom endpoint URL</li>
    </ul>
</script>
